{"cells":[{"cell_type":"markdown","metadata":{"id":"TL5y5fY9Jy_x"},"source":["\n","\n","# Lab 2: Neural networks \n","\n","In this lab we will build dense neural networks on the MNIST dataset.\n","\n","`https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html`"]},{"cell_type":"markdown","metadata":{"id":"95IUFjlWhjTZ"},"source":["## Load the data and create train-test splits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b3VdFJ2hjTZ"},"outputs":[],"source":["# Auto-setup when running on Google Colab\n","if 'google.colab' in str(get_ipython()):\n","    !pip install openml\n","\n","# Global imports and settings\n","%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import openml as oml\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.neural_network import MLPClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTT01rxWhjTa"},"outputs":[],"source":["# Download MNIST data. Takes a while the first time.\n","mnist = oml.datasets.get_dataset(554)\n","X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute, dataset_format='array');\n","X = X.reshape(70000, 28, 28)\n","\n","# Take some random examples\n","from random import randint\n","fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n","for i in range(5):\n","    n = randint(0,70000)\n","    axes[i].imshow(X[n], cmap=plt.cm.gray_r)\n","    axes[i].set_xticks([])\n","    axes[i].set_yticks([])\n","    axes[i].set_xlabel(\"{}\".format(y[n]))\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZlvdpyYKx7V"},"outputs":[],"source":["# For MNIST, there exists a predefined stratified train-test split of 60000-10000. We therefore don't shuffle or stratify here.\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=6000, random_state=0, test_size = 1000 )\n"]},{"cell_type":"markdown","metadata":{"id":"8ldP-5z1B2vL"},"source":["## Exercise 1: Preprocessing\n","* Normalize the data: map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. \n","* Store the floating-point values in `x_train_normalized` and `x_test_normalized`.\n","* Map the class label to a one-hot-encoded value. Store in `y_train_encoded` and `y_test_encoded`."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"g8HC-TDgB1D1"},"outputs":[],"source":["# Solution\n","x_train_normalized = X_train / 255.0\n","x_test_normalized = X_test / 255.0\n","\n","from sklearn.preprocessing import OneHotEncoder\n","ohe = OneHotEncoder()\n","y_train_encoded = ohe.fit_transform(y_train.reshape(-1,1)).toarray()\n","y_test_encoded = ohe.fit_transform(y_test.reshape(-1,1)).toarray()\n","y_train_encoded[:2]"]},{"cell_type":"code","source":["#flatten the data \n","x_train_normalized = x_train_normalized.reshape(6000,-1)\n","x_test_normalized  = x_test_normalized.reshape(1000,-1)\n"],"metadata":{"id":"5StivzWSxnxu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3014ezH3C7jT"},"source":["## Exercise 2: Create a MLPClassifier model\n","\n","Implement a `create_model` function which defines the topography of the deep neural net, specifying the following:\n","\n","* The number of layers in the deep neural net: Use 2 dense layers for now.\n","* The number of nodes in each layer: these are parameters of your function.\n","* Any regularization layers. \n","* The optimizer and learning rate. Make the learning rate a parameter of your function as well.\n","\n","Consider:\n","* What should be the shape of the input layer?\n","* Which activation function you will need for the last layer, since this is a 10-class classification problem?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCTC5FEDhjTc"},"outputs":[],"source":["### Create and compile a 'deep' neural net\n","def create_model(layer_1=32, layer_2=10, learning_rate=0.001, activation='relu' ):\n","    pass"]},{"cell_type":"code","source":["# Solution\n","def create_model(layer_1=32, layer_2=10, learning_rate=0.001, activation='relu'):\n","      \n","   model = MLPClassifier(hidden_layer_sizes=(layer_1,layer_2),\n","                    random_state=5,\n","                    verbose=True,\n","                    learning_rate_init= learning_rate,\n","                    activation= activation)\n","   return model\n"],"metadata":{"id":"AjSjoKTSqa1O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ew3d0oFJhjTd"},"source":["## Exercise 3: Create a training function\n","Implement a `train_model` function which trains."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwbEokGShjTd"},"outputs":[],"source":["def train_model(model, X, y):\n","    \"\"\"\n","    model: the model to train\n","    X, y: the training data and labels\n","\n","    \"\"\"\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NViN0IhRhjTd"},"outputs":[],"source":["# Solution\n","def train_model(model, x_train, y_train):\n","    \"\"\"\n","    model: the model to train\n","    X, y: the training data and labels\n","\n","    \"\"\"\n","\n","    T_MLP = model.fit(x_train, y_train)\n","     \n","    return T_MLP "]},{"cell_type":"code","source":[],"metadata":{"id":"so8s5efzvFTX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-IXYVfvM4gD"},"source":["## Exercise 4: Evaluate the model\n","\n","Train the model with a learning rate of 0.003. \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"nj3v5EKQFY8s"},"outputs":[],"source":["# Solution\n"," \n","learning_rate = 0.003\n","\n","# Create the model the model's topography.\n","model = create_model(layer_1=32, layer_2=10, learning_rate=0.001, activation='relu')\n","\n","# Train the model on the normalized training set.\n","trained_model = train_model(model, x_train_normalized, y_train_encoded)\n","\n","\n","# Evaluate against the test set.\n"," \n","print (\"\\n The accuracy is \",trained_model.score(x_test_normalized,y_test_encoded))\n"," "]},{"cell_type":"markdown","metadata":{"id":"Y5IKmk7D49_n"},"source":["## Exercise 5: Optimize the model\n","\n","Try to optimize the model, either manually or with a tuning method. At least optimize the following:\n","* the number of hidden layers \n","* the number of nodes in each layer\n"," \n","\n","Try to reach at least 96% accuracy against the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"wYG5qXpP5a9n"},"outputs":[],"source":["# Solution\n","\n"," \n","\n","# Create the model\n","model = create_model(layer_1=800, layer_2=800, learning_rate=0.003, activation='relu')\n","\n","# Train the model on the normalized training set.\n","trained_model = train_model(model, x_train_normalized, y_train_encoded)\n","\n","\n","# Evaluate against the test set.\n"," \n","print (\"\\n The accuracy is \",trained_model.score(x_test_normalized,y_test_encoded))\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6Tyw-gihjTe"},"outputs":[],"source":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}