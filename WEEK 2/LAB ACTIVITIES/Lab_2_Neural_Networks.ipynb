{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "\n",
        "\n",
        "# Lab 2: Neural networks\n",
        "\n",
        "In this lab we will build dense neural networks on the MNIST dataset.\n",
        "\n",
        "`https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95IUFjlWhjTZ"
      },
      "source": [
        "## Load the data and create train-test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b3VdFJ2hjTZ"
      },
      "outputs": [],
      "source": [
        "# Auto-setup when running on Google Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install openml\n",
        "\n",
        "# Global imports and settings\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import openml as oml\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTT01rxWhjTa"
      },
      "outputs": [],
      "source": [
        "# Download MNIST data. Takes a while the first time.\n",
        "mnist = oml.datasets.get_dataset(554)\n",
        "X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute, dataset_format='array');\n",
        "X = X.reshape(70000, 28, 28)\n",
        "\n",
        "# Take some random examples\n",
        "from random import randint\n",
        "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
        "for i in range(5):\n",
        "    n = randint(0,70000)\n",
        "    axes[i].imshow(X[n], cmap=plt.cm.gray_r)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_yticks([])\n",
        "    axes[i].set_xlabel(\"{}\".format(y[n]))\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZlvdpyYKx7V"
      },
      "outputs": [],
      "source": [
        "# For MNIST, there exists a predefined stratified train-test split of 60000-10000. We therefore don't shuffle or stratify here.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=6000, random_state=0, test_size = 1000 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldP-5z1B2vL"
      },
      "source": [
        "## Exercise 1: Preprocessing\n",
        "* Normalize the data: map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0.\n",
        "* Store the floating-point values in `x_train_normalized` and `x_test_normalized`.\n",
        "* Map the class label to a one-hot-encoded value. Store in `y_train_encoded` and `y_test_encoded`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Assuming x_train, x_test, y_train, and y_test are your training and testing data\n",
        "\n",
        "# Normalize features\n",
        "X_train_normalized = X_train / 255.0\n",
        "X_test_normalized = X_test / 255.0\n",
        "\n",
        "# Perform one-hot encoding for class labels\n",
        "encoder = OneHotEncoder(categories='auto', sparse=False)\n",
        "\n",
        "# Reshape the labels to be column vectors\n",
        "y_train_reshaped = y_train.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "# Fit and transform the training labels\n",
        "y_train_encoded = encoder.fit_transform(y_train_reshaped)\n",
        "\n",
        "# Transform the testing labels\n",
        "y_test_encoded = encoder.transform(y_test_reshaped)\n"
      ],
      "metadata": {
        "id": "rJXFZq_f0SXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Exercise 2: Create a MLPClassifier model\n",
        "\n",
        "Implement a `create_model` function which defines the topography of the deep neural net, specifying the following:\n",
        "\n",
        "* The number of layers in the deep neural net: Use 2 dense layers for now.\n",
        "* The number of nodes in each layer: these are parameters of your function.\n",
        "* Any regularization layers.\n",
        "* The optimizer and learning rate. Make the learning rate a parameter of your function as well.\n",
        "\n",
        "Consider:\n",
        "* What should be the shape of the input layer?\n",
        "* Which activation function you will need for the last layer, since this is a 10-class classification problem?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def create_model(hidden_layer_sizes=(32, 10), activation='relu', learning_rate_init=0.003):\n",
        "\n",
        "\n",
        "    # Initialize the MLPClassifier model\n",
        "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
        "                          activation=activation,\n",
        "                          learning_rate_init=learning_rate_init)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "hidden_layer_sizes = (32, 10)  # Number of nodes in each hidden layer\n",
        "activation = 'relu'  # Activation function for the hidden layers\n",
        "learning_rate_init = 0.003  # Learning rate for the optimizer\n",
        "model = create_model(hidden_layer_sizes, activation, learning_rate_init)\n"
      ],
      "metadata": {
        "id": "ezW7RoNQ32sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCTC5FEDhjTc"
      },
      "outputs": [],
      "source": [
        "### Create and compile a 'deep' neural net\n",
        "def create_model(layer_1=32, layer_2=10, learning_rate=0.003, activation='relu' ):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew3d0oFJhjTd"
      },
      "source": [
        "## Exercise 3: Create a training function\n",
        "Implement a `train_model` function which trains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwbEokGShjTd"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X, y):\n",
        "    \"\"\"\n",
        "    model: the model to train\n",
        "    X, y: the training data and labels\n",
        "\n",
        "    \"\"\"\n",
        "    trained_model = model.fit(X, y)\n",
        "    return trained_model\n",
        "    trained_model = train_model(model, X_train, y_train)\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Exercise 4: Evaluate the model\n",
        "\n",
        "Train the model with a learning rate of 0.003.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define the learning rate\n",
        "learning_rate = 0.003\n",
        "\n",
        "# Create an instance of MLPClassifier with the specified learning rate\n",
        "model = MLPClassifier(learning_rate_init=learning_rate, max_iter=1000)\n",
        "# Reshape X_train if necessary\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Reshape X_train if necessary\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Evaluate the trained model on the test set\n",
        "accuracy = model.score(X_test, y_test)\n",
        "\n",
        "# Print the test set accuracy\n",
        "print(\"Test set accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "J9XG4UAbAPi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5IKmk7D49_n"
      },
      "source": [
        "## Exercise 5: Optimize the model\n",
        "\n",
        "Try to optimize the model, either manually or with a tuning method. At least optimize the following:\n",
        "* the number of hidden layers\n",
        "* the number of nodes in each layer\n",
        "\n",
        "\n",
        "Try to reach at least 96% accuracy against the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Assume you have already imported necessary libraries and loaded your dataset\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform data preprocessing if necessary, such as scaling or encoding categorical variables\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(30,), (60,), (30, 30), (60, 60)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate_init': [0.001, 0.003, 0.01]\n",
        "}\n",
        "\n",
        "# Create an instance of MLPClassifier\n",
        "mlp = MLPClassifier(max_iter=100)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test set accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "kaBo34MBH-Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Tyw-gihjTe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}